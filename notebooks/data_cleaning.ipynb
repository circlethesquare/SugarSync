{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f14e3cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../diabetes+130-us+hospitals+for+years+1999-2008/diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b81138",
   "metadata": {},
   "source": [
    "## data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbf35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are other typesof Null values in the data but starting with checking \n",
    "#the ones system recognize \n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a62d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"max_glu_serum column is {(df['max_glu_serum'].isnull().sum()*100 / len(df['max_glu_serum'])).round(2)}% empty\")\n",
    "print(f\"A1Cresult column is {(df['A1Cresult'].isnull().sum()*100 / len(df['A1Cresult'])).round(2)}% empty\")\n",
    "\n",
    "#as these columns are mostly empty, dropping them & creating a copy of original df \n",
    "df_cleaned = df.copy()\n",
    "df_cleaned.drop(columns=[\"max_glu_serum\",\"A1Cresult\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning raw data columns per dtype \n",
    "\n",
    "numeric_columns = df_cleaned.select_dtypes(\"number\")\n",
    "categorical_columns = df_cleaned.select_dtypes(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_question_marks_with_nan(df):\n",
    "    \"\"\" Defining a function to replace '?' with NaN \"\"\"\n",
    "    return df.replace('?', np.NaN, inplace=True)\n",
    "\n",
    "\n",
    "replace_question_marks_with_nan(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicated but result is 0 \n",
    "df_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns 'diag_1' 'diag_2', 'diag_3' have a lot unique columns which are\n",
    "#codes for spesific diagnoses. Will drop these columns but later \n",
    "#might look into again by themselves. \n",
    "\n",
    "#also medical_specialty & payer_code columns are irrelevant, so will drop them as well \n",
    "\n",
    "#and to keep things simple, dropping discharge_disposition_id & admission_source_id \n",
    "\n",
    "columns_to_remove = ['diag_1',\n",
    "                     'diag_2',\n",
    "                     'diag_3',\n",
    "                     'medical_specialty',\n",
    "                     'payer_code',\n",
    "                     'discharge_disposition_id',\n",
    "                     'admission_source_id',\n",
    "                     'admission_type_id'\n",
    "                    ]\n",
    "\n",
    "\n",
    "df_cleaned.drop(columns_to_remove,\n",
    "                axis=1,\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('../partially_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd938c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.crosstab(df['readmitted'], df['age']).apply(lambda c: c / c.sum() * 100, axis=0).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_columns_to_readmitted(df):\n",
    "    for column in df.columns:\n",
    "        if column != 'readmitted':\n",
    "            cross_tab = pd.crosstab(df['readmitted'], df[column]).apply(lambda c: c / c.sum() * 100, axis=0).round(2)\n",
    "            print(f\"Cross-tabulation of 'readmitted' and '{column}':\")\n",
    "            print(cross_tab)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7683fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_columns_to_readmitted(df.select_dtypes('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78eefff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68789b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749ceaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in binary_columns:\n",
    "    print(column,df_cleaned[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_binary_values(df, columns):\n",
    "    \"\"\"defining a function to change binary columns into numeric 0 -1 \"\"\"\n",
    "    for column in binary_columns:\n",
    "        df[column] = df[column].replace({'No': 0,\n",
    "                                         'Steady': 1,\n",
    "                                         'Yes': 1,\n",
    "                                         'Ch':1})\n",
    "\n",
    "\n",
    "replace_binary_values(df_cleaned,binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a327cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now will try to assing numeric values for other columns that has \n",
    "#more than 2 unique (yes/no) values \n",
    "\n",
    "for column in other_columns:\n",
    "    print(column,df_cleaned[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also removing these column names from my list \n",
    "\n",
    "other_columns = [col for col in other_columns if col not in columns_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in other_columns: \n",
    "    print(column,df_cleaned[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c766bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for binary columns and non-binary columns to check for null values \n",
    "#that system does not check fot categorical columns \n",
    "\n",
    "binary_columns = []\n",
    "other_columns = []\n",
    "for column in categorical_columns.columns:\n",
    "    if len(categorical_columns[column].unique()) == 2: \n",
    "        binary_columns.append(column)\n",
    "    else: \n",
    "        other_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9217c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf96931",
   "metadata": {},
   "source": [
    "#using label encoding for age column and dropping the original one \n",
    "\n",
    "#label_encoder = LabelEncoder()\n",
    "\n",
    "#df_cleaned['age_encoded'] = label_encoder.fit_transform(df_cleaned['age'])\n",
    "\n",
    "for label, original_bin in enumerate(label_encoder.classes_):\n",
    "    print(f\"{original_bin}: {label}\")\n",
    "\n",
    "df_cleaned.drop('age', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f9474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "575561b6",
   "metadata": {},
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform 'weight' column\n",
    "df['weight_encoded'] = label_encoder.fit_transform(df['weight'])\n",
    "\n",
    "# Print the mapping between original bins and encoded values\n",
    "for label, original_bin in enumerate(label_encoder.classes_):\n",
    "    print(f\"{original_bin}: {label}\")\n",
    "\n",
    "# Optionally, you can drop the original 'weight' column\n",
    "# df.drop('weight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cleaned[df_cleaned['weight'] == '?'])/len(df_cleaned[df_cleaned['weight'] != '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbd568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sugarsync",
   "language": "python",
   "name": "sugarsync"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
